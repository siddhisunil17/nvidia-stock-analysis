# nvidia-stock-analysis

---

## ğŸ—‚ï¸ Overview

This project analyzes **NVIDIA stock price data (July 2022 â€“ July 2024)** using Python.  
The assignment explores **big-data processing**, **feature engineering**, **data visualization**, and **machine learning** techniques including **KMeans Clustering** and **LSTM regression**.

All code is written in a **Jupyter Notebook** and accompanied by a detailed report.

---

## ğŸ¯ Objectives

- Load and clean real-world stock data  
- Engineer features (returns, moving average, normalized volume)  
- Create meaningful visualizations using matplotlib and seaborn  
- Apply unsupervised learning (KMeans)  
- Build LSTM-based time series forecasting model

---



## ğŸ“ Project Structure

- `notebook/HW1_DIC.ipynb`: Main Jupyter Notebook containing all data processing and ML code  
- `report/Nvidia_Stock_Analysis_Report.pdf`: Final PDF report with explanations, visualizations, and insights  
- `data/NVDA.csv`: Historical stock price data for NVIDIA  
- `requirements.txt`: List of Python packages needed to run the notebook  
- `README.md`: This file

  ---

## ğŸ§ª Key Tasks Performed

### ğŸ”¹ Part 1: Big Data Processing

- Cleaned missing values in stock data using forward fill and median techniques  
- Converted date formats for consistency  
- Calculated basic statistics (min, max, mean, median, std deviation)  
- Engineered features like daily returns and 7-day moving average  
- Normalized trading volume using Min-Max scaling  
- Visualized trends using histograms, boxplots, and heatmaps  

### ğŸ”¹ Part 2: Machine Learning

- Applied **KMeans Clustering** on normalized daily return, adjusted close, and volume  
- Identified and interpreted 3 clusters representing different market behaviors  
- Built an **LSTM model** using TensorFlow to predict closing prices  
- Evaluated model using Mean Squared Error and visual comparison  


---

## ğŸ“Š Libraries Used

- `pandas` â€“ for data manipulation and analysis  
- `numpy` â€“ for numerical computations  
- `matplotlib` & `seaborn` â€“ for visualizations  
- `scikit-learn` â€“ for clustering and preprocessing  
- `tensorflow` â€“ for building and training the LSTM model  

To install all dependencies, run:

pip install -r requirements.txt



